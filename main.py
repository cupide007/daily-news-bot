import feedparser
import requests
import os
import shutil
from datetime import datetime
import pytz
import time
import random

# --- ğŸ› ï¸ é…ç½®åŒºï¼šåœ¨è¿™é‡Œæ·»åŠ ä½ æƒ³çœ‹çš„ RSS æº ---
RSS_SOURCES = [
    {"name": "36æ°ª", "url": "https://36kr.com/feed"},
    {"name": "å°‘æ•°æ´¾", "url": "https://sspai.com/feed"},
    # æƒ³è¦åŠ  ITä¹‹å®¶ï¼Ÿå¤åˆ¶ä¸‹é¢è¿™è¡Œï¼š
    {"name": "ITä¹‹å®¶", "url": "https://www.ithome.com/rss/"},
    # æƒ³è¦åŠ  è™å—…ï¼Ÿ
    {"name": "è™å—…", "url": "https://www.huxiu.com/rss/0.xml"},
]
API_KEY = os.environ.get("GEMINI_API_KEY")

# --- AI è°ƒç”¨å°è£… ---
def call_gemini(prompt):
    if not API_KEY:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° GEMINI_API_KEY")
        return None
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key={API_KEY}"
    headers = {'Content-Type': 'application/json'}
    # å®‰å…¨è®¾ç½®æ”¾è¡Œ
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
    ]
    
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": safety_settings
    }
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                return result['candidates'][0]['content']['parts'][0]['text']
    except Exception as e:
        print(f"Network Error: {e}")
    return None

def generate_overview(titles):
    prompt = f"""
    è¯·æ ¹æ®ä»¥ä¸‹æ–°é—»æ ‡é¢˜ï¼Œå†™ä¸€æ®µ150å­—å·¦å³çš„ã€ç§‘æŠ€èˆ†æƒ…ç»¼è¿°ã€‘ã€‚
    è¦æ±‚ï¼šè¯­æ°”ä¸“ä¸šã€å®¢è§‚ã€‚ä¸è¦åˆ†ç‚¹ï¼Œå†™æˆä¸€æ®µè¿è´¯çš„æ–‡å­—ã€‚
    æ ‡é¢˜åˆ—è¡¨ï¼š
    {titles}
    """
    return call_gemini(prompt)

def generate_summary(content):
    prompt = f"""
    è¯·å¯¹è¿™æ¡æ–°é—»è¿›è¡Œæç®€æ€»ç»“ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼Œå¹¶æå–1ä¸ªæ ¸å¿ƒæ ‡ç­¾ã€‚
    æ ¼å¼è¦æ±‚ï¼šæ‘˜è¦å†…å®¹|æ ‡ç­¾
    æ–°é—»å†…å®¹ï¼š
    {content[:800]}
    """
    return call_gemini(prompt)

def main():
    # 1. å‡†å¤‡ç›®å½•
    posts_dir = "docs/posts"
    if not os.path.exists(posts_dir): os.makedirs(posts_dir)

    tz = pytz.timezone('Asia/Shanghai')
    today = datetime.now(tz).strftime("%Y-%m-%d")
    now_time = datetime.now(tz).strftime("%H:%M")

    # 2. å¾ªç¯æŠ“å–æ‰€æœ‰æº
    all_entries = []
    
    print(f"ğŸš€ å¼€å§‹æŠ“å– {len(RSS_SOURCES)} ä¸ªæº...")
    
    for source in RSS_SOURCES:
        try:
            print(f"   æ­£åœ¨æŠ“å–: {source['name']}...")
            feed = feedparser.parse(source['url'])
            if not feed.entries: continue
            
            # åªå–æ¯ä¸ªæºçš„å‰ 5 æ¡ï¼Œé˜²æ­¢å¤„ç†æ—¶é—´è¿‡é•¿
            for entry in feed.entries[:5]:
                # æŠŠæ¥æºåå­—å¡è¿› entry å¯¹è±¡é‡Œï¼Œåé¢è¦ç”¨
                entry['source_name'] = source['name']
                all_entries.append(entry)
        except Exception as e:
            print(f"   âŒ {source['name']} æŠ“å–å¤±è´¥: {e}")

    # 3. æ··åˆä¸æ’åº
    # å°è¯•æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ— (å¦‚æœ RSS é‡Œæœ‰æ ‡å‡†æ—¶é—´å­—æ®µ)
    # å¦‚æœæ²¡æœ‰æ—¶é—´å­—æ®µï¼Œå°±éšæœºæ‰“ä¹±ä¸€ç‚¹ï¼Œæ˜¾å¾—æ¯”è¾ƒä¸°å¯Œ
    try:
        all_entries.sort(key=lambda x: x.published_parsed if 'published_parsed' in x and x.published_parsed else time.localtime(), reverse=True)
    except:
        random.shuffle(all_entries)

    # æœ€ç»ˆåªå–å‰ 12 æ¡è¿›è¡Œ AI å¤„ç† (æ§åˆ¶æˆæœ¬å’Œæ—¶é—´)
    final_entries = all_entries[:12]
    titles_list = [e.title for e in final_entries]

    # 4. ç”Ÿæˆå®è§‚ç»¼è¿°
    print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå®è§‚ç»¼è¿°...")
    overview_text = generate_overview("\n".join(titles_list))
    if not overview_text: overview_text = "ä»Šæ—¥æš‚æ— ç»¼è¿°ã€‚"
    overview_text = overview_text.replace("\n", "").replace('"', "'")

    # 5. æ‹¼æ¥ Markdown (ä¿æŒ Plan A çš„å•è¡Œ HTML é£æ ¼)
    md = f"# ğŸ“… èˆ†æƒ…æ—¥æŠ¥ {today}\n\n"
    md += f'<div class="update-time">æ›´æ–°äºåŒ—äº¬æ—¶é—´ {now_time}</div>\n\n'
    md += f'<div class="daily-overview"><h3>ğŸ›¡ï¸ å…¨ç½‘èˆ†æƒ…ç»¼è¿°</h3><p>{overview_text}</p></div>\n\n'
    md += '<div class="news-list">\n\n'

    # 6. å¤„ç†æ¯æ¡æ–°é—»
    for i, entry in enumerate(final_entries):
        source_name = entry.get('source_name', 'èµ„è®¯')
        print(f"[{i+1}/{len(final_entries)}] å¤„ç† [{source_name}]: {entry.title}")
        
        content = entry.summary if 'summary' in entry else entry.title
        ai_res = generate_summary(content)
        
        summary = "AI æš‚æœªç”Ÿæˆæ‘˜è¦"
        tag = "çƒ­ç‚¹"
        
        if ai_res and "|" in ai_res:
            parts = ai_res.split("|")
            summary = parts[0].strip().replace("\n", "")
            if len(parts) > 1: tag = parts[1].strip()
        elif ai_res:
            summary = ai_res.replace("\n", "")

        # ç”Ÿæˆå¡ç‰‡ (å•è¡Œ HTMLï¼Œé˜²æ­¢ç¼©è¿›é”™è¯¯)
        # æ³¨æ„ï¼šè¿™é‡ŒæŠŠ '36Kr' æ¢æˆäº†åŠ¨æ€çš„ {source_name}
        card_html = f'<div class="news-card"><h4><a href="{entry.link}" target="_blank">{entry.title}</a></h4><div class="summary">{summary}</div><div class="news-meta"><span class="tag-pill">{tag}</span><span class="source-name">{source_name}</span></div></div>'
        
        md += card_html + "\n\n"
        time.sleep(1) # ä¼‘æ¯ä¸€ä¸‹ï¼Œé˜²é™æµ

    md += '</div>\n'

    # 7. ä¿å­˜
    file_path = os.path.join(posts_dir, f"{today}.md")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(md)
    shutil.copy(file_path, os.path.join(posts_dir, "latest.md"))
    print(f"âœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(final_entries)} æ¡ç®€æŠ¥")

if __name__ == "__main__":
    main()
